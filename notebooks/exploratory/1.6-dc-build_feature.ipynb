{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45c7e9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bcfadd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 12:19:19.598340: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/opt/anaconda3/lib/\n",
      "2023-05-24 12:19:19.598368: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Basics\\nimport pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport keras.backend as K\\nimport tensorflow as tf\\n\\n# Data\\nimport xarray as xr\\nimport h5py\\nimport pickle\\n\\n# Helpful\\nimport time\\nimport datetime\\nimport itertools\\nfrom itertools import product\\nfrom tqdm import tqdm\\nimport os\\n\\n# My Methods\\nimport importlib\\nfrom src.utils.CRPS import *\\nfrom src.utils.data_split import *\\nfrom src.models.EMOS import *\\nimport data.raw.load_data_raw as ldr\\nimport data.processed.load_data_processed as ldp\\nfrom src.models.EMOS_global.EMOS_global_load_models import *\";\n",
       "                var nbb_formatted_code = \"# Basics\\nimport pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport keras.backend as K\\nimport tensorflow as tf\\n\\n# Data\\nimport xarray as xr\\nimport h5py\\nimport pickle\\n\\n# Helpful\\nimport time\\nimport datetime\\nimport itertools\\nfrom itertools import product\\nfrom tqdm import tqdm\\nimport os\\n\\n# My Methods\\nimport importlib\\nfrom src.utils.CRPS import *\\nfrom src.utils.data_split import *\\nfrom src.models.EMOS import *\\nimport data.raw.load_data_raw as ldr\\nimport data.processed.load_data_processed as ldp\\nfrom src.models.EMOS_global.EMOS_global_load_models import *\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Basics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "# Data\n",
    "import xarray as xr\n",
    "import h5py\n",
    "import pickle\n",
    "\n",
    "# Helpful\n",
    "import time\n",
    "import datetime\n",
    "import itertools\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# My Methods\n",
    "import importlib\n",
    "from src.utils.CRPS import *\n",
    "from src.utils.data_split import *\n",
    "from src.models.EMOS import *\n",
    "import data.raw.load_data_raw as ldr\n",
    "import data.processed.load_data_processed as ldp\n",
    "from src.models.EMOS_global.EMOS_global_load_models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f71e657",
   "metadata": {},
   "source": [
    "## Goal: Make ws10 feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039d3ee4",
   "metadata": {},
   "source": [
    "### 0. Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c57a2ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"var_names = [\\\"u10\\\", \\\"v10\\\", \\\"t2m\\\", \\\"t850\\\", \\\"z500\\\"]\";\n",
       "                var nbb_formatted_code = \"var_names = [\\\"u10\\\", \\\"v10\\\", \\\"t2m\\\", \\\"t850\\\", \\\"z500\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var_names = [\"u10\", \"v10\", \"t2m\", \"t850\", \"z500\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba381f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# Variables to make testing easier --> determines variable and lead_time\\nvar = 0  # 0,...,4\\nlead_time = 1  # 0,...,30\\nforecast_date = 0\\nlat = 0\\nlon = 0\";\n",
       "                var nbb_formatted_code = \"# Variables to make testing easier --> determines variable and lead_time\\nvar = 0  # 0,...,4\\nlead_time = 1  # 0,...,30\\nforecast_date = 0\\nlat = 0\\nlon = 0\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Variables to make testing easier --> determines variable and lead_time\n",
    "var = 0  # 0,...,4\n",
    "lead_time = 1  # 0,...,30\n",
    "forecast_date = 0\n",
    "lat = 0\n",
    "lon = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927dbe78",
   "metadata": {},
   "source": [
    "### 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "442244f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"dat_raw = ldr.load_data_raw()  # list length 5 with 2018 - 2022\\n\\n# processed data\\ndat_train_proc_norm = ldp.load_data_all_train_proc_norm()\\ndat_test_proc_norm = ldp.load_data_all_test_proc_norm()\";\n",
       "                var nbb_formatted_code = \"dat_raw = ldr.load_data_raw()  # list length 5 with 2018 - 2022\\n\\n# processed data\\ndat_train_proc_norm = ldp.load_data_all_train_proc_norm()\\ndat_test_proc_norm = ldp.load_data_all_test_proc_norm()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dat_raw = ldr.load_data_raw()  # list length 5 with 2018 - 2022\n",
    "\n",
    "# processed data\n",
    "dat_train_proc_norm = ldp.load_data_all_train_proc_norm()\n",
    "dat_test_proc_norm = ldp.load_data_all_test_proc_norm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f5a483",
   "metadata": {},
   "source": [
    "### 2. Test if mean is enough, or have to do everything from scratch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67aabb6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"u10_test_ens = (\\n    dat_raw[0]\\n    .isel(forecast_date=forecast_date, lead_time=lead_time, var=0, lat=lat, lon=lon)\\n    .values\\n)\\nv10_test_ens = (\\n    dat_raw[0]\\n    .isel(forecast_date=forecast_date, lead_time=lead_time, var=1, lat=lat, lon=lon)\\n    .values\\n)\\nu10_test_mean = (\\n    dat_train_proc_norm[0]\\n    .u10_train.isel(\\n        forecast_date=forecast_date, lead_time=lead_time, lat=lat, lon=lon, mean_std=0\\n    )\\n    .values\\n)\\nv10_test_mean = (\\n    dat_train_proc_norm[1]\\n    .v10_train.isel(\\n        forecast_date=forecast_date, lead_time=lead_time, lat=lat, lon=lon, mean_std=0\\n    )\\n    .values\\n)\\nu10_test_std = (\\n    dat_train_proc_norm[0]\\n    .u10_train.isel(\\n        forecast_date=forecast_date, lead_time=lead_time, lat=lat, lon=lon, mean_std=1\\n    )\\n    .values\\n)\\nv10_test_std = (\\n    dat_train_proc_norm[1]\\n    .v10_train.isel(\\n        forecast_date=forecast_date, lead_time=lead_time, lat=lat, lon=lon, mean_std=1\\n    )\\n    .values\\n)\";\n",
       "                var nbb_formatted_code = \"u10_test_ens = (\\n    dat_raw[0]\\n    .isel(forecast_date=forecast_date, lead_time=lead_time, var=0, lat=lat, lon=lon)\\n    .values\\n)\\nv10_test_ens = (\\n    dat_raw[0]\\n    .isel(forecast_date=forecast_date, lead_time=lead_time, var=1, lat=lat, lon=lon)\\n    .values\\n)\\nu10_test_mean = (\\n    dat_train_proc_norm[0]\\n    .u10_train.isel(\\n        forecast_date=forecast_date, lead_time=lead_time, lat=lat, lon=lon, mean_std=0\\n    )\\n    .values\\n)\\nv10_test_mean = (\\n    dat_train_proc_norm[1]\\n    .v10_train.isel(\\n        forecast_date=forecast_date, lead_time=lead_time, lat=lat, lon=lon, mean_std=0\\n    )\\n    .values\\n)\\nu10_test_std = (\\n    dat_train_proc_norm[0]\\n    .u10_train.isel(\\n        forecast_date=forecast_date, lead_time=lead_time, lat=lat, lon=lon, mean_std=1\\n    )\\n    .values\\n)\\nv10_test_std = (\\n    dat_train_proc_norm[1]\\n    .v10_train.isel(\\n        forecast_date=forecast_date, lead_time=lead_time, lat=lat, lon=lon, mean_std=1\\n    )\\n    .values\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "u10_test_ens = (\n",
    "    dat_raw[0]\n",
    "    .isel(forecast_date=forecast_date, lead_time=lead_time, var=0, lat=lat, lon=lon)\n",
    "    .values\n",
    ")\n",
    "v10_test_ens = (\n",
    "    dat_raw[0]\n",
    "    .isel(forecast_date=forecast_date, lead_time=lead_time, var=1, lat=lat, lon=lon)\n",
    "    .values\n",
    ")\n",
    "u10_test_mean = (\n",
    "    dat_train_proc_norm[0]\n",
    "    .u10_train.isel(\n",
    "        forecast_date=forecast_date, lead_time=lead_time, lat=lat, lon=lon, mean_std=0\n",
    "    )\n",
    "    .values\n",
    ")\n",
    "v10_test_mean = (\n",
    "    dat_train_proc_norm[1]\n",
    "    .v10_train.isel(\n",
    "        forecast_date=forecast_date, lead_time=lead_time, lat=lat, lon=lon, mean_std=0\n",
    "    )\n",
    "    .values\n",
    ")\n",
    "u10_test_std = (\n",
    "    dat_train_proc_norm[0]\n",
    "    .u10_train.isel(\n",
    "        forecast_date=forecast_date, lead_time=lead_time, lat=lat, lon=lon, mean_std=1\n",
    "    )\n",
    "    .values\n",
    ")\n",
    "v10_test_std = (\n",
    "    dat_train_proc_norm[1]\n",
    "    .v10_train.isel(\n",
    "        forecast_date=forecast_date, lead_time=lead_time, lat=lat, lon=lon, mean_std=1\n",
    "    )\n",
    "    .values\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c6b133",
   "metadata": {},
   "source": [
    "### 3. From raw data make ws10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5af1426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 120, 130)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"dat_raw[0].predictions.isel(forecast_date=0, lead_time=0, var=0).shape\";\n",
       "                var nbb_formatted_code = \"dat_raw[0].predictions.isel(forecast_date=0, lead_time=0, var=0).shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dat_raw[0].predictions.isel(forecast_date=0, lead_time=0, var=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5419b47a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"ws10_2018 = np.hypot(\\n    dat_raw[0].predictions.isel(lead_time=0, var=0),\\n    dat_raw[0].predictions.isel(lead_time=0, var=1),\\n)\";\n",
       "                var nbb_formatted_code = \"ws10_2018 = np.hypot(\\n    dat_raw[0].predictions.isel(lead_time=0, var=0),\\n    dat_raw[0].predictions.isel(lead_time=0, var=1),\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ws10_2018 = np.hypot(\n",
    "    dat_raw[0].predictions.isel(lead_time=0, var=0),\n",
    "    dat_raw[0].predictions.isel(lead_time=0, var=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97b21fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"ws10_2018_truth = np.hypot(\\n    dat_raw[0].ground_truth.isel(forecast_date=0, lead_time=0, var=0),\\n    dat_raw[0].ground_truth.isel(forecast_date=0, lead_time=0, var=1),\\n)\";\n",
       "                var nbb_formatted_code = \"ws10_2018_truth = np.hypot(\\n    dat_raw[0].ground_truth.isel(forecast_date=0, lead_time=0, var=0),\\n    dat_raw[0].ground_truth.isel(forecast_date=0, lead_time=0, var=1),\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ws10_2018_truth = np.hypot(\n",
    "    dat_raw[0].ground_truth.isel(forecast_date=0, var=0),\n",
    "    dat_raw[0].ground_truth.isel(forecast_date=0, var=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64bf759e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"len(ldr.load_data_raw()[0:4])\";\n",
       "                var nbb_formatted_code = \"len(ldr.load_data_raw()[0:4])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(ldr.load_data_raw()[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba77741",
   "metadata": {},
   "source": [
    "### 4. Make denonormalized ws10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b5506ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"def denormalize(mean, std, x):\\n    denormalized = (x * std) + mean\\n    return denormalized\\n\\n\\ndef make_ws10_train_denormed():\\n\\n    # Define path and file names for the h5 file to be created\\n    path = \\\"/Data/Delong_BA_Data/mean_ens_std_denorm/ws10_train_denorm.h5\\\"\\n    f = h5py.File(path, \\\"a\\\")\\n    name_train = \\\"ws10_train\\\"\\n    name_truth = \\\"ws10_truth\\\"\\n\\n    # load global means and stds\\n    means = np.load(\\n        \\\"/mnt/sda/Data2/fourcastnet/data/stats_v0/global_means.npy\\\"\\n    ).flatten()[[0, 1, 2, 5, 14]]\\n    stds = np.load(\\n        \\\"/mnt/sda/Data2/fourcastnet/data/stats_v0/global_stds.npy\\\"\\n    ).flatten()[[0, 1, 2, 5, 14]]\\n\\n    # Load raw data for the years 2018-2021\\n    # process one year at a time\\n    for year in tqdm(range(4)):\\n        dat_raw = ldr.load_data_raw()[year]  # load data for the year\\n        n_days = dat_raw.predictions.shape[0]  # get number of days\\n\\n        # Create the datasets within the h5 file for 'train' and 'truth' data\\n        # Create them once, before entering the forecast_date loop\\n        if name_train in f:\\n            del f[name_train]  # delete the dataset if it already exists\\n        if name_truth in f:\\n            del f[name_truth]  # delete the dataset if it already exists\\n\\n        train = f.create_dataset(\\n            name_train,\\n            (n_days, *dat_raw.predictions.isel(var=0, forecast_date=0).shape),\\n            dtype=np.float32,\\n            compression=\\\"gzip\\\",\\n            compression_opts=9,\\n        )\\n        truth = f.create_dataset(\\n            name_truth,\\n            (n_days, *dat_raw.ground_truth.isel(var=0, forecast_date=0).shape),\\n            dtype=np.float32,\\n            compression=\\\"gzip\\\",\\n            compression_opts=9,\\n        )\\n\\n        for forecast_date in tqdm(range(n_days)):\\n            # Compute the magnitude (absolute value) of wind speed predictions and truths\\n            u10_year_date_pred = denormalize(\\n                means[0],\\n                stds[0],\\n                dat_raw.predictions.isel(var=0, forecast_date=forecast_date),\\n            )\\n            v10_year_date_pred = denormalize(\\n                means[1],\\n                stds[1],\\n                dat_raw.predictions.isel(var=1, forecast_date=forecast_date),\\n            )\\n            ws10_pred = np.hypot(\\n                u10_year_date_pred,\\n                v10_year_date_pred,\\n            )\\n            u10_year_date_truth = denormalize(\\n                means[0],\\n                stds[0],\\n                dat_raw.ground_truth.isel(var=1, forecast_date=forecast_date),\\n            )\\n            v10_year_date_truth = denormalize(\\n                means[1],\\n                stds[1],\\n                dat_raw.ground_truth.isel(var=0, forecast_date=forecast_date),\\n            )\\n            \\n            \\n            ws10_tru = np.hypot(\\n                u10_year_date_truth,\\n                v10_year_date_truth,\\n            )\";\n",
       "                var nbb_formatted_code = \"def denormalize(mean, std, x):\\n    denormalized = (x * std) + mean\\n    return denormalized\\n\\n\\ndef make_ws10_train_denormed():\\n\\n    # Define path and file names for the h5 file to be created\\n    path = \\\"/Data/Delong_BA_Data/mean_ens_std_denorm/ws10_train_denorm.h5\\\"\\n    f = h5py.File(path, \\\"a\\\")\\n    name_train = \\\"ws10_train\\\"\\n    name_truth = \\\"ws10_truth\\\"\\n\\n    # load global means and stds\\n    means = np.load(\\n        \\\"/mnt/sda/Data2/fourcastnet/data/stats_v0/global_means.npy\\\"\\n    ).flatten()[[0, 1, 2, 5, 14]]\\n    stds = np.load(\\n        \\\"/mnt/sda/Data2/fourcastnet/data/stats_v0/global_stds.npy\\\"\\n    ).flatten()[[0, 1, 2, 5, 14]]\\n\\n    # Load raw data for the years 2018-2021\\n    # process one year at a time\\n    for year in tqdm(range(4)):\\n        dat_raw = ldr.load_data_raw()[year]  # load data for the year\\n        n_days = dat_raw.predictions.shape[0]  # get number of days\\n\\n        # Create the datasets within the h5 file for 'train' and 'truth' data\\n        # Create them once, before entering the forecast_date loop\\n        if name_train in f:\\n            del f[name_train]  # delete the dataset if it already exists\\n        if name_truth in f:\\n            del f[name_truth]  # delete the dataset if it already exists\\n\\n        train = f.create_dataset(\\n            name_train,\\n            (n_days, *dat_raw.predictions.isel(var=0, forecast_date=0).shape),\\n            dtype=np.float32,\\n            compression=\\\"gzip\\\",\\n            compression_opts=9,\\n        )\\n        truth = f.create_dataset(\\n            name_truth,\\n            (n_days, *dat_raw.ground_truth.isel(var=0, forecast_date=0).shape),\\n            dtype=np.float32,\\n            compression=\\\"gzip\\\",\\n            compression_opts=9,\\n        )\\n\\n        for forecast_date in tqdm(range(n_days)):\\n            # Compute the magnitude (absolute value) of wind speed predictions and truths\\n            u10_year_date_pred = denormalize(\\n                means[0],\\n                stds[0],\\n                dat_raw.predictions.isel(var=0, forecast_date=forecast_date),\\n            )\\n            v10_year_date_pred = denormalize(\\n                means[1],\\n                stds[1],\\n                dat_raw.predictions.isel(var=1, forecast_date=forecast_date),\\n            )\\n            ws10_pred = np.hypot(u10_year_date_pred, v10_year_date_pred,)\\n            u10_year_date_truth = denormalize(\\n                means[0],\\n                stds[0],\\n                dat_raw.ground_truth.isel(var=1, forecast_date=forecast_date),\\n            )\\n            v10_year_date_truth = denormalize(\\n                means[1],\\n                stds[1],\\n                dat_raw.ground_truth.isel(var=0, forecast_date=forecast_date),\\n            )\\n\\n            ws10_tru = np.hypot(u10_year_date_truth, v10_year_date_truth,)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def denormalize(mean, std, x):\n",
    "    denormalized = (x * std) + mean\n",
    "    return denormalized\n",
    "\n",
    "\n",
    "def make_ws10_train_denormed():\n",
    "\n",
    "    # Define path and file names for the h5 file to be created\n",
    "    path = \"/Data/Delong_BA_Data/mean_ens_std_denorm/ws10_train_denorm.h5\"\n",
    "    f = h5py.File(path, \"a\")\n",
    "    name_train = \"ws10_train\"\n",
    "    name_truth = \"ws10_truth\"\n",
    "\n",
    "    # load global means and stds\n",
    "    means = np.load(\n",
    "        \"/mnt/sda/Data2/fourcastnet/data/stats_v0/global_means.npy\"\n",
    "    ).flatten()[[0, 1, 2, 5, 14]]\n",
    "    stds = np.load(\n",
    "        \"/mnt/sda/Data2/fourcastnet/data/stats_v0/global_stds.npy\"\n",
    "    ).flatten()[[0, 1, 2, 5, 14]]\n",
    "\n",
    "    # Load raw data for the years 2018-2021\n",
    "    # process one year at a time\n",
    "    for year in tqdm(range(4)):\n",
    "        dat_raw = ldr.load_data_raw()[year]  # load data for the year\n",
    "        n_days = dat_raw.predictions.shape[0]  # get number of days\n",
    "\n",
    "        # Create the datasets within the h5 file for 'train' and 'truth' data\n",
    "        # Create them once, before entering the forecast_date loop\n",
    "        if name_train in f:\n",
    "            del f[name_train]  # delete the dataset if it already exists\n",
    "        if name_truth in f:\n",
    "            del f[name_truth]  # delete the dataset if it already exists\n",
    "\n",
    "        train = f.create_dataset(\n",
    "            name_train,\n",
    "            (n_days, *dat_raw.predictions.isel(var=0, forecast_date=0).shape),\n",
    "            dtype=np.float32,\n",
    "            compression=\"gzip\",\n",
    "            compression_opts=9,\n",
    "        )\n",
    "        truth = f.create_dataset(\n",
    "            name_truth,\n",
    "            (n_days, *dat_raw.ground_truth.isel(var=0, forecast_date=0).shape),\n",
    "            dtype=np.float32,\n",
    "            compression=\"gzip\",\n",
    "            compression_opts=9,\n",
    "        )\n",
    "\n",
    "        for forecast_date in tqdm(range(n_days)):\n",
    "            # Compute the magnitude (absolute value) of wind speed predictions and truths\n",
    "            u10_year_date_pred = denormalize(\n",
    "                means[0],\n",
    "                stds[0],\n",
    "                dat_raw.predictions.isel(var=0, forecast_date=forecast_date),\n",
    "            )\n",
    "            v10_year_date_pred = denormalize(\n",
    "                means[1],\n",
    "                stds[1],\n",
    "                dat_raw.predictions.isel(var=1, forecast_date=forecast_date),\n",
    "            )\n",
    "            ws10_pred = np.hypot(u10_year_date_pred, v10_year_date_pred,)\n",
    "            \n",
    "            u10_year_date_truth = denormalize(\n",
    "                means[0],\n",
    "                stds[0],\n",
    "                dat_raw.ground_truth.isel(var=1, forecast_date=forecast_date),\n",
    "            )\n",
    "            v10_year_date_truth = denormalize(\n",
    "                means[1],\n",
    "                stds[1],\n",
    "                dat_raw.ground_truth.isel(var=0, forecast_date=forecast_date),\n",
    "            )\n",
    "\n",
    "            ws10_tru = np.hypot(u10_year_date_truth, v10_year_date_truth,)\n",
    "            \n",
    "            # Calculate mean and standard deviation of wind speed predictions\n",
    "            ws10_pred_mean = ws10_pred.mean(dim=\"ens\")\n",
    "            ws10_pred_std = ws10_pred.std(dim=\"ens\")\n",
    "\n",
    "            # Concatenate mean and standard deviation data along new 'mean_std' dimension\n",
    "            ws_train = xr.concat([ws10_pred_mean, ws10_pred_std], dim=\"mean_std\")\n",
    "            ws_train = ws_train.transpose(\"lead_time\", \"lat\", \"lon\", \"mean_std\")\n",
    "\n",
    "            # Populate the h5 file with the data\n",
    "            train[forecast_date, ...] = ws_train\n",
    "            truth[forecast_date, ...] = ws10_tru\n",
    "\n",
    "    # Close the h5 file\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ae0e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6109be4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
