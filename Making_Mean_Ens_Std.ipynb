{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0839c076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db036e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 22:32:25.599276: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/opt/anaconda3/lib/\n",
      "2023-05-13 22:32:25.599303: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Basics\\nimport pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n# Data\\nimport xarray as xr\\nimport h5py\\n\\n# Helpful\\nimport time\\nimport datetime\\nimport itertools\\nfrom itertools import product\\n\\n# My Methods\\nimport importlib\\nimport CRPS\\nimport EMOS\\nfrom CRPS import *\\nfrom EMOS import *\";\n",
       "                var nbb_formatted_code = \"# Basics\\nimport pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n# Data\\nimport xarray as xr\\nimport h5py\\n\\n# Helpful\\nimport time\\nimport datetime\\nimport itertools\\nfrom itertools import product\\n\\n# My Methods\\nimport importlib\\nimport CRPS\\nimport EMOS\\nfrom CRPS import *\\nfrom EMOS import *\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Basics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data\n",
    "import xarray as xr\n",
    "import h5py\n",
    "\n",
    "# Helpful\n",
    "import time\n",
    "import datetime\n",
    "import itertools\n",
    "from itertools import product\n",
    "\n",
    "# My Methods\n",
    "import importlib\n",
    "import CRPS\n",
    "import EMOS\n",
    "from CRPS import *\n",
    "from EMOS import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5886e629",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'EMOS' from '/home/dchen/BA_CH_EN/EMOS.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"importlib.reload(CRPS)\\nimportlib.reload(EMOS)\";\n",
       "                var nbb_formatted_code = \"importlib.reload(CRPS)\\nimportlib.reload(EMOS)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importlib.reload(CRPS)\n",
    "importlib.reload(EMOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb43896d",
   "metadata": {},
   "source": [
    "#### Goal:\n",
    "Goal of this notebook is the making of 10 Datasets from the existing 5 Datasets. <br>\n",
    "Divided into training and test dataset for each variable, with the ensemble forecast replaced by ens_mean and ens_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09140dac",
   "metadata": {},
   "source": [
    "#### 1. Load Necessary Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "522f948d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# Load all data\\ndat_2018 = xr.open_dataset(\\n    \\\"/mnt/sda/Data2/fourcastnet/data/predictions/ensemble_2018.h5\\\"\\n).isel(phony_dim_5=slice(1, 51))\\ndat_2019 = xr.open_dataset(\\n    \\\"/mnt/sda/Data2/fourcastnet/data/predictions/ensemble_2019.h5\\\"\\n).isel(phony_dim_5=slice(1, 51))\\ndat_2020 = xr.open_dataset(\\n    \\\"/mnt/sda/Data2/fourcastnet/data/predictions/ensemble_2020.h5\\\"\\n).isel(phony_dim_5=slice(1, 51))\\ndat_2021 = xr.open_dataset(\\n    \\\"/mnt/sda/Data2/fourcastnet/data/predictions/ensemble_2021.h5\\\"\\n).isel(phony_dim_5=slice(1, 51))\\ndat_2022 = xr.open_dataset(\\n    \\\"/mnt/sda/Data2/fourcastnet/data/predictions/ensemble_2022.h5\\\"\\n).isel(phony_dim_5=slice(1, 51))\";\n",
       "                var nbb_formatted_code = \"# Load all data\\ndat_2018 = xr.open_dataset(\\n    \\\"/mnt/sda/Data2/fourcastnet/data/predictions/ensemble_2018.h5\\\"\\n).isel(phony_dim_5=slice(1, 51))\\ndat_2019 = xr.open_dataset(\\n    \\\"/mnt/sda/Data2/fourcastnet/data/predictions/ensemble_2019.h5\\\"\\n).isel(phony_dim_5=slice(1, 51))\\ndat_2020 = xr.open_dataset(\\n    \\\"/mnt/sda/Data2/fourcastnet/data/predictions/ensemble_2020.h5\\\"\\n).isel(phony_dim_5=slice(1, 51))\\ndat_2021 = xr.open_dataset(\\n    \\\"/mnt/sda/Data2/fourcastnet/data/predictions/ensemble_2021.h5\\\"\\n).isel(phony_dim_5=slice(1, 51))\\ndat_2022 = xr.open_dataset(\\n    \\\"/mnt/sda/Data2/fourcastnet/data/predictions/ensemble_2022.h5\\\"\\n).isel(phony_dim_5=slice(1, 51))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load all data\n",
    "dat_2018 = xr.open_dataset(\n",
    "    \"/mnt/sda/Data2/fourcastnet/data/predictions/ensemble_2018.h5\"\n",
    ").isel(phony_dim_5=slice(1, 51))\n",
    "dat_2019 = xr.open_dataset(\n",
    "    \"/mnt/sda/Data2/fourcastnet/data/predictions/ensemble_2019.h5\"\n",
    ").isel(phony_dim_5=slice(1, 51))\n",
    "dat_2020 = xr.open_dataset(\n",
    "    \"/mnt/sda/Data2/fourcastnet/data/predictions/ensemble_2020.h5\"\n",
    ").isel(phony_dim_5=slice(1, 51))\n",
    "dat_2021 = xr.open_dataset(\n",
    "    \"/mnt/sda/Data2/fourcastnet/data/predictions/ensemble_2021.h5\"\n",
    ").isel(phony_dim_5=slice(1, 51))\n",
    "dat_2022 = xr.open_dataset(\n",
    "    \"/mnt/sda/Data2/fourcastnet/data/predictions/ensemble_2022.h5\"\n",
    ").isel(phony_dim_5=slice(1, 51))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62ccc163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"dat_train_all = [dat_2018, dat_2019, dat_2020, dat_2021]\\nvar_names = [\\\"v10\\\", \\\"t2m\\\", \\\"t850\\\", \\\"z500\\\"]\";\n",
       "                var nbb_formatted_code = \"dat_train_all = [dat_2018, dat_2019, dat_2020, dat_2021]\\nvar_names = [\\\"v10\\\", \\\"t2m\\\", \\\"t850\\\", \\\"z500\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dat_train_all = [dat_2018, dat_2019, dat_2020, dat_2021]\n",
    "var_names = [\"v10\", \"t2m\", \"t850\", \"z500\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8795786",
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in range(len(var_names)):\n",
    "    # Set up for file\n",
    "    start_time = time.time()\n",
    "    path = \"/Data/Delong_BA_Data/Mean_ens_std/\" + var_names[var] + '_train.h5'\n",
    "    f = h5py.File(path, \"a\")\n",
    "    name_train = var_names[var] + '_train'\n",
    "    name_truth = var_names[var] + '_truth'\n",
    "    \n",
    "    \n",
    "    # Concatening the different years\n",
    "    x_train_mean = xr.concat([dat_2018.predictions.isel(phony_dim_2 = var).mean(dim = \"phony_dim_5\"),\n",
    "                             dat_2019.predictions.isel(phony_dim_2 = var).mean(dim = \"phony_dim_5\"),\n",
    "                             dat_2020.predictions.isel(phony_dim_2 = var).mean(dim = \"phony_dim_5\"),\n",
    "                             dat_2021.predictions.isel(phony_dim_2 = var).mean(dim = \"phony_dim_5\")],\n",
    "                             dim = \"phony_dim_0\")\n",
    "    x_train_std = xr.concat([dat_2018.predictions.isel(phony_dim_2 = var).std(dim = \"phony_dim_5\"),\n",
    "                             dat_2019.predictions.isel(phony_dim_2 = var).std(dim = \"phony_dim_5\"),\n",
    "                             dat_2020.predictions.isel(phony_dim_2 = var).std(dim = \"phony_dim_5\"),\n",
    "                             dat_2021.predictions.isel(phony_dim_2 = var).std(dim = \"phony_dim_5\")],\n",
    "                             dim = \"phony_dim_0\")\n",
    "    x_train = xr.concat([x_train_mean, x_train_std], dim=\"mean_std\")\n",
    "    x_train = x_train.transpose(\n",
    "    \"phony_dim_0\", \"phony_dim_1\", \"phony_dim_3\", \"phony_dim_4\", \"mean_std\"\n",
    ")\n",
    "\n",
    "    y_train = xr.concat([dat_2018.ground_truth.isel(phony_dim_2 = var),\n",
    "                         dat_2019.ground_truth.isel(phony_dim_2 = var),\n",
    "                         dat_2020.ground_truth.isel(phony_dim_2 = var),\n",
    "                         dat_2021.ground_truth.isel(phony_dim_2 = var)],\n",
    "                         dim = \"phony_dim_0\")\n",
    "    \n",
    "    n_days, n_lead_times, lat, long, mean_var = x_train.shape\n",
    "    \n",
    "    half_time = time.time()\n",
    "    time_difference_half = half_time - start_time\n",
    "    hours = int(time_difference_half // 3600)\n",
    "    minutes = int((time_difference_half % 3600) // 60)\n",
    "    seconds = int(time_difference_half % 60)\n",
    "    formatted_time_half = f\" Round {var} finished concatenation in:{hours} hours, {minutes} minutes, {seconds} seconds\"\n",
    "    print(f\"{formatted_time_half}\")\n",
    "    \n",
    "    # Create those files\n",
    "    try:\n",
    "        train = f.create_dataset(\n",
    "            name_train,\n",
    "            shape=(n_days, n_lead_times, lat, long, mean_var),\n",
    "            dtype=np.float32,\n",
    "            compression=\"gzip\",\n",
    "            compression_opts=9,\n",
    "        )\n",
    "    except:\n",
    "        del f[name_train]\n",
    "        train = f.create_dataset(\n",
    "            name_train,\n",
    "            shape=(n_days, n_lead_times, lat, long, mean_var),\n",
    "            dtype=np.float32,\n",
    "            compression=\"gzip\",\n",
    "            compression_opts=9,\n",
    "        )\n",
    "    try:\n",
    "        truth = f.create_dataset(\n",
    "            name_truth,\n",
    "            shape=(n_days, n_lead_times, lat, long),\n",
    "            dtype=np.float32,\n",
    "            compression=\"gzip\",\n",
    "            compression_opts=9,\n",
    "        )\n",
    "    except:\n",
    "        del f[name_truth]\n",
    "        truth = f.create_dataset(\n",
    "            name_truth,\n",
    "            shape=(n_days, n_lead_times, lat, long),\n",
    "            dtype=np.float32,\n",
    "            compression=\"gzip\",\n",
    "            compression_opts=9,\n",
    "        )\n",
    "        \n",
    "        \n",
    "    # Put Data inside of files\n",
    "    for i in range(n_days):\n",
    "        train[i, ...] = x_train.loc[i, ...]\n",
    "        truth[i, ...] = y_train[i, ...]\n",
    "        \n",
    "    end_time = time.time()\n",
    "    time_difference = end_time - start_time\n",
    "    hours = int(time_difference // 3600)\n",
    "    minutes = int((time_difference % 3600) // 60)\n",
    "    seconds = int(time_difference % 60)\n",
    "    formatted_time = f\" Round {var} finished in:{hours} hours, {minutes} minutes, {seconds} seconds\"\n",
    "    print(f\"{formatted_time}\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abda0634",
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in range(5):\n",
    "    # Set up for file\n",
    "    start_time = time.time()\n",
    "    path = \"/Data/Delong_BA_Data/Mean_ens_std/\" + var_names[var] + '_test.h5'\n",
    "    f = h5py.File(path, \"a\")\n",
    "    name_test = var_names[var] + '_test'\n",
    "    name_truth = var_names[var] + 'test_truth'\n",
    "    \n",
    "    x_test_mean = dat_2022.predictions.isel(phony_dim_2=var).mean(dim=\"phony_dim_5\")\n",
    "    x_test_std = dat_2022.predictions.isel(phony_dim_2=var).std(dim=\"phony_dim_5\")\n",
    "    \n",
    "    x_test = xr.concat([x_test_mean, x_test_std], dim=\"mean_std\")\n",
    "    x_test = x_test.transpose(\n",
    "    \"phony_dim_0\", \"phony_dim_1\", \"phony_dim_3\", \"phony_dim_4\", \"mean_std\"\n",
    ")\n",
    "\n",
    "    y_test = dat_2022.ground_truth.isel(phony_dim_2 = var)\n",
    "    \n",
    "    n_days, n_lead_times, lat, long, mean_var = x_test.shape\n",
    "    \n",
    "    half_time = time.time()\n",
    "    time_difference_half = half_time - start_time\n",
    "    hours = int(time_difference_half // 3600)\n",
    "    minutes = int((time_difference_half % 3600) // 60)\n",
    "    seconds = int(time_difference_half % 60)\n",
    "    formatted_time_half = f\" Round {var} finished concatenation in:{hours} hours, {minutes} minutes, {seconds} seconds\"\n",
    "    print(f\"{formatted_time_half}\")\n",
    "    \n",
    "    # Create those files\n",
    "    try:\n",
    "        test = f.create_dataset(\n",
    "            name_test,\n",
    "            shape=(n_days, n_lead_times, lat, long, mean_var),\n",
    "            dtype=np.float32,\n",
    "            compression=\"gzip\",\n",
    "            compression_opts=9,\n",
    "        )\n",
    "    except:\n",
    "        del f[name_test]\n",
    "        test = f.create_dataset(\n",
    "            name_test,\n",
    "            shape=(n_days, n_lead_times, lat, long, mean_var),\n",
    "            dtype=np.float32,\n",
    "            compression=\"gzip\",\n",
    "            compression_opts=9,\n",
    "        )\n",
    "    try:\n",
    "        truth = f.create_dataset(\n",
    "            name_truth,\n",
    "            shape=(n_days, n_lead_times, lat, long),\n",
    "            dtype=np.float32,\n",
    "            compression=\"gzip\",\n",
    "            compression_opts=9,\n",
    "        )\n",
    "    except:\n",
    "        del f[name_truth]\n",
    "        truth = f.create_dataset(\n",
    "            name_truth,\n",
    "            shape=(n_days, n_lead_times, lat, long),\n",
    "            dtype=np.float32,\n",
    "            compression=\"gzip\",\n",
    "            compression_opts=9,\n",
    "        )\n",
    "        \n",
    "        \n",
    "    # Put Data inside of files\n",
    "    for i in range(n_days):\n",
    "        test[i, ...] = x_test.loc[i, ...]\n",
    "        truth[i, ...] = y_test[i, ...]\n",
    "        \n",
    "    end_time = time.time()\n",
    "    time_difference = end_time - start_time\n",
    "    hours = int(time_difference // 3600)\n",
    "    minutes = int((time_difference % 3600) // 60)\n",
    "    seconds = int(time_difference % 60)\n",
    "    formatted_time = f\" Round {var} finished in:{hours} hours, {minutes} minutes, {seconds} seconds\"\n",
    "    print(f\"{formatted_time}\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95c88c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4167e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c2b211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7873e300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec31dec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c4a0be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfea7f15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9332a522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bb433a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f992f4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8381da0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0700004",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
